{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning week - Day 1 - Playground\n",
    "\n",
    "### Exercise objectives:\n",
    "\n",
    "- Get a visual representation of Neural Networks\n",
    "- Get a better intuition of what Neural Networks are doing\n",
    "\n",
    "<hr>\n",
    "<hr>\n",
    "\n",
    "This first exercise does not require much code. It is your starting point into the Deep Learning journey.\n",
    "\n",
    "As things are clearer with a visual representation, let's dig into the Tensorflow playground that allows you to play with some parts of a Neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - The data\n",
    "\n",
    "Let's go on the [Playground](https://playground.tensorflow.org/#activation=tanh&batchSize=10&dataset=circle&regDataset=reg-plane&learningRate=0.03&regularizationRate=0&noise=0&networkShape=4,2&seed=0.13983&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false&regularization_hide=true&showTestData_hide=false&stepButton_hide=false&activation_hide=true&problem_hide=false&batchSize_hide=true&dataset_hide=false&resetButton_hide=false&discretize_hide=false&playButton_hide=false&learningRate_hide=true&regularizationRate_hide=true&percTrainData_hide=false&numHiddenLayers_hide=false) and select the following type of data : \n",
    "\n",
    "- A classification problem \n",
    "- The circle dataset (blue dots inside a circle of oranges dots)\n",
    "- Ratio of training to test data : 70%\n",
    "- No noise (=0)\n",
    "- Do not show test data (right panel) and do not discretize the output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - The features\n",
    "\n",
    "Here, select only the features $X_1$ and $X_2$ - unselect the other features if necessary.\n",
    "\n",
    "❓ Question ❓ In the case where you use the other variables, as $X_1^{2}$, $X_2^{2}$, $X_1 X_2$, $sin(X_1)$ and $sin(X_2)$, what type of classic Machine Learning operation does it corresponds to?\n",
    "\n",
    "Answer : It corresponds to some type of feature engineering where you transform them (by multiplication or by applying a sinus).\n",
    "\n",
    "Here, in this exercise but also tomorrow, we will only use the raw input features $X_1$ and $X_2$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - The model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a model that has : \n",
    "- three hidden layers\n",
    "- 5 neurons on the first hidden layer\n",
    "- 4 neurons on the second hidden layer\n",
    "- 3 neurons on the last hidden layer\n",
    "\n",
    "Note that here, the output layer is not represented.\n",
    "\n",
    "❓ Question ❓ Given the problem at hand, what is this output layer doing? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "classifying the samples according to the results of the neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 - Run \n",
    "\n",
    "Now that you have defined your model, you can run (play arrow on the top left) to optimize the weights of your model in order to classify your data points.\n",
    "\n",
    "❓ Question ❓ What do you think about your results?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pretty good"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 - Neural network in Keras\n",
    "\n",
    "Let's write (almost) the same model - at least the architecture - in Keras. It will corresponds to the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T10:24:38.478783Z",
     "start_time": "2020-11-16T10:22:03.716322Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.3.1-cp38-cp38-manylinux2010_x86_64.whl (320.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 320.5 MB 1.2 kB/s eta 0:00:015     |███████████████████████████▌    | 275.3 MB 3.2 MB/s eta 0:00:15\n",
      "\u001b[?25hRequirement already satisfied: six>=1.12.0 in /home/florent/.pyenv/versions/3.8.5/envs/lewagon/lib/python3.8/site-packages (from tensorflow) (1.15.0)\n",
      "Collecting keras-preprocessing<1.2,>=1.1.1\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "\u001b[K     |████████████████████████████████| 42 kB 99 kB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting tensorboard<3,>=2.3.0\n",
      "  Downloading tensorboard-2.4.0-py3-none-any.whl (10.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 10.6 MB 124 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting google-pasta>=0.1.8\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[K     |████████████████████████████████| 57 kB 2.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting astunparse==1.6.3\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting absl-py>=0.7.0\n",
      "  Downloading absl_py-0.11.0-py3-none-any.whl (127 kB)\n",
      "\u001b[K     |████████████████████████████████| 127 kB 4.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting numpy<1.19.0,>=1.16.0\n",
      "  Downloading numpy-1.18.5-cp38-cp38-manylinux1_x86_64.whl (20.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 20.6 MB 5.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /home/florent/.pyenv/versions/3.8.5/envs/lewagon/lib/python3.8/site-packages (from tensorflow) (1.12.1)\n",
      "Collecting h5py<2.11.0,>=2.10.0\n",
      "  Downloading h5py-2.10.0-cp38-cp38-manylinux1_x86_64.whl (2.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.9 MB 5.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorflow-estimator<2.4.0,>=2.3.0\n",
      "  Downloading tensorflow_estimator-2.3.0-py2.py3-none-any.whl (459 kB)\n",
      "\u001b[K     |████████████████████████████████| 459 kB 2.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting gast==0.3.3\n",
      "  Downloading gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "\u001b[K     |████████████████████████████████| 65 kB 1.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting protobuf>=3.9.2\n",
      "  Downloading protobuf-3.14.0-cp38-cp38-manylinux1_x86_64.whl (1.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.0 MB 2.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting termcolor>=1.1.0\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Collecting grpcio>=1.8.6\n",
      "  Downloading grpcio-1.33.2-cp38-cp38-manylinux2014_x86_64.whl (3.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.8 MB 3.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting wheel>=0.26\n",
      "  Downloading wheel-0.35.1-py2.py3-none-any.whl (33 kB)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/florent/.pyenv/versions/3.8.5/envs/lewagon/lib/python3.8/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (47.1.0)\n",
      "Collecting werkzeug>=0.11.15\n",
      "  Downloading Werkzeug-1.0.1-py2.py3-none-any.whl (298 kB)\n",
      "\u001b[K     |████████████████████████████████| 298 kB 3.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.3.3-py3-none-any.whl (96 kB)\n",
      "\u001b[K     |████████████████████████████████| 96 kB 2.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests<3,>=2.21.0 in /home/florent/.pyenv/versions/3.8.5/envs/lewagon/lib/python3.8/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (2.24.0)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.7.0-py3-none-any.whl (779 kB)\n",
      "\u001b[K     |████████████████████████████████| 779 kB 6.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting google-auth<2,>=1.6.3\n",
      "  Downloading google_auth-1.23.0-py2.py3-none-any.whl (114 kB)\n",
      "\u001b[K     |████████████████████████████████| 114 kB 5.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.2-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/florent/.pyenv/versions/3.8.5/envs/lewagon/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (1.25.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /home/florent/.pyenv/versions/3.8.5/envs/lewagon/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/florent/.pyenv/versions/3.8.5/envs/lewagon/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2020.6.20)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/florent/.pyenv/versions/3.8.5/envs/lewagon/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2.10)\n",
      "Collecting cachetools<5.0,>=2.0.0\n",
      "  Downloading cachetools-4.1.1-py3-none-any.whl (10 kB)\n",
      "Collecting rsa<5,>=3.1.4; python_version >= \"3.5\"\n",
      "  Downloading rsa-4.6-py3-none-any.whl (47 kB)\n",
      "\u001b[K     |████████████████████████████████| 47 kB 1.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "\u001b[K     |████████████████████████████████| 155 kB 2.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Collecting pyasn1>=0.1.3\n",
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "\u001b[K     |████████████████████████████████| 77 kB 2.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.1.0-py2.py3-none-any.whl (147 kB)\n",
      "\u001b[K     |████████████████████████████████| 147 kB 1.6 MB/s eta 0:00:01\n",
      "\u001b[?25hUsing legacy 'setup.py install' for termcolor, since package 'wheel' is not installed.\n",
      "Installing collected packages: numpy, keras-preprocessing, grpcio, werkzeug, absl-py, markdown, tensorboard-plugin-wit, wheel, cachetools, pyasn1, rsa, pyasn1-modules, google-auth, oauthlib, requests-oauthlib, google-auth-oauthlib, protobuf, tensorboard, google-pasta, astunparse, h5py, tensorflow-estimator, gast, opt-einsum, termcolor, tensorflow\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.19.2\n",
      "    Uninstalling numpy-1.19.2:\n",
      "      Successfully uninstalled numpy-1.19.2\n",
      "    Running setup.py install for termcolor ... \u001b[?25ldone\n",
      "\u001b[?25hSuccessfully installed absl-py-0.11.0 astunparse-1.6.3 cachetools-4.1.1 gast-0.3.3 google-auth-1.23.0 google-auth-oauthlib-0.4.2 google-pasta-0.2.0 grpcio-1.33.2 h5py-2.10.0 keras-preprocessing-1.1.2 markdown-3.3.3 numpy-1.18.5 oauthlib-3.1.0 opt-einsum-3.3.0 protobuf-3.14.0 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-oauthlib-1.3.0 rsa-4.6 tensorboard-2.4.0 tensorboard-plugin-wit-1.7.0 tensorflow-2.3.1 tensorflow-estimator-2.3.0 termcolor-1.1.0 werkzeug-1.0.1 wheel-0.35.1\n"
     ]
    }
   ],
   "source": [
    "# !pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T10:24:40.866428Z",
     "start_time": "2020-11-16T10:24:38.490740Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Dense(5, input_dim=2)) # First hidden layer with 5 neurons\n",
    "model.add(layers.Dense(4)) # Second hidden layer with 4 neurons\n",
    "model.add(layers.Dense(3)) # Third hidden layer with 3 neurons\n",
    "\n",
    "model.add(layers.Dense(1, activation='sigmoid')) # Output layer that outputs a probability which is\n",
    "                                                 # necessary in the case of a 2 class classification problem\n",
    "\n",
    "# For now, let's skip the model.compile() and the model.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `input_dim` of the first layer corresponds to the number of input features, which is 2 here, $X_1$ and $X_2$. It is mandatory for the first layer. The fact that you here define a `Sequential` model makes the following layer aware of the input size based on the output size of the previous layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 - Change the dataset\n",
    "\n",
    "Here, you can change the dataset for the \"Exclusive Or\".\n",
    "\n",
    "❓ Question ❓ Find on the Playground a model with two hidden layers (the number of neurons per layer is for you to choose) that has a very small loss.\n",
    "\n",
    "❓ Question ❓ Once you have your model on Playground, write it with the Keras library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T10:27:46.737386Z",
     "start_time": "2020-11-16T10:27:46.690621Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Dense(3, input_dim = 2))\n",
    "model.add(layers.Dense(2))\n",
    "model.add(layers.Dense(1, activation = 'sigmoid'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ Question ❓ Repeat the same process with the two other datasets (Gaussian & Spiral). Once you have found a good network on Playground, write its Keras counterpart.\n",
    "\n",
    "Hint : You should be able to have a model that works on the Gaussian dataset with only one hidden layer\n",
    "\n",
    "N.B. : You can play with the noise in the data to see its effect on the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T10:28:47.124245Z",
     "start_time": "2020-11-16T10:28:47.100136Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Dense(1, input_dim = 2))\n",
    "model.add(layers.Dense(1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T10:29:37.881117Z",
     "start_time": "2020-11-16T10:29:37.830521Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Dense(5, input_dim = 2))\n",
    "model.add(layers.Dense(4))\n",
    "model.add(layers.Dense(3))\n",
    "model.add(layers.Dense(2))\n",
    "model.add(layers.Dense(1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7 - Activation Function\n",
    "\n",
    "Compared to the lecture, there is one slight difference : we haven't dealt with the activation function, which is the slight modification that is done to the output of each of the linear regression at each neuron.\n",
    "\n",
    "Click on this new link of the [Playground](https://playground.tensorflow.org/#activation=tanh&batchSize=10&dataset=spiral&regDataset=reg-plane&learningRate=0.03&regularizationRate=0&noise=0&networkShape=2&seed=0.23545&showTestData=false&discretize=false&percTrainData=70&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false&regularization_hide=true&showTestData_hide=false&stepButton_hide=false&activation_hide=false&problem_hide=false&batchSize_hide=true&dataset_hide=false&resetButton_hide=false&discretize_hide=false&playButton_hide=false&learningRate_hide=true&regularizationRate_hide=true&percTrainData_hide=false&numHiddenLayers_hide=false) that integrates the possibility to select the activation function.\n",
    "\n",
    "❓ Question ❓ With the spiral dataset, play with the activation function to see how it affects the outputs of the model.\n",
    "\n",
    "❗ **First Practice Rule** ❗ In general, choose the `relu` activation function! It appears to work better for many problems.\n",
    "\n",
    "The Playground allows you to select the only one activation function for **all** the hidden layers, which means all the neurons from all the hidden layers will have the same activation function.\n",
    "\n",
    "In Keras, you can choose one activation function per layer. It writes : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Dense(6, activation='relu', input_dim=2)) # First hidden layer with 6 neurons\n",
    "model.add(layers.Dense(5, activation='relu')) # Second hidden layer with 5 neurons\n",
    "model.add(layers.Dense(4, activation='relu')) # Third hidden layer with 4 neurons\n",
    "\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ Question ❓ For the sake of practice, write a Keras model with three hidden layers. The first hidden layer has 10 neurons and a `tanh` (Hyperbolic tangent) as activation function. The second layer has 7 neurons and a `relu` activation function. \n",
    "\n",
    "As you have a two-class classification problem, the output layer is a dense layer with one output, and an activation function being `sigmoid` (to get a probability)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T10:34:37.848509Z",
     "start_time": "2020-11-16T10:34:37.776277Z"
    }
   },
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Dense(10, activation='tanh', input_dim=2)) # First hidden layer with 6 neurons\n",
    "model.add(layers.Dense(7, activation='relu')) # Second hidden layer with 5 neurons\n",
    "model.add(layers.Dense(4)) # Third hidden layer with 4 neurons\n",
    "\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8 - Regression\n",
    "\n",
    "Now, switch the problem type to a regression problem. \n",
    "\n",
    "On the one hand, you will have to choose the number of layers, number of neurons and activation functions of your model. On the other hand, the last layer is not of you to choose, it is dictated by the type of problem you have. Therefore, instead of \n",
    "\n",
    "`model.add(layers.Dense(1, activation='sigmoid'))`\n",
    "\n",
    "you need to have\n",
    "\n",
    "`model.add(layers.Dense(1, activation='linear'))`\n",
    "\n",
    "meaning that you output 1 final value which is between $ -\\infty$ and $+ \\infty$ \n",
    "\n",
    "- Advance note #1 (that we will see again later) : The last layer of a multiclass problem with 13 classes is \n",
    "\n",
    "`model.add(layers.Dense(13, activation='softmax'))`\n",
    "\n",
    "- Advance note #2 (that we will see again later) : The last layer of a regression problem with 7 outputs is \n",
    "\n",
    "`model.add(layers.Dense(7, activation='linear'))`\n",
    "\n",
    "\n",
    "❓ Question ❓ Find on Playground a neural network that works well in the case of regression data. Once you have found it, write its architecture in Keras : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T10:37:54.872013Z",
     "start_time": "2020-11-16T10:37:54.812442Z"
    }
   },
   "outputs": [],
   "source": [
    "#for simple plane\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(1, input_dim=2)) \n",
    "model.add(layers.Dense(1, activation='linear'))\n",
    "\n",
    "#for multi-gaussion\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(5, input_dim=2)) \n",
    "model.add(layers.Dense(4)) \n",
    "model.add(layers.Dense(3))\n",
    "model.add(layers.Dense(1, activation='linear'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9 - Do not hesitate to play ...\n",
    "\n",
    "... with various datasets and architecture to grasp the ideas underlying Deep Learning\n",
    "\n",
    "### But do not worry if you didn't understand everything, you still have the entire week for that.\n",
    "\n",
    "__________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You are now ready to do the same things with Keras directly !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
